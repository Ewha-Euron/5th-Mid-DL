합성곱 신경망<br>
1. 컴퓨터비전<br>
종류<br>
- image classification : 고양이인지 아닌지<br>
- object detection : 어느 위치에 차가 있는지. 차가 여러대일 수 있다<br>
- neural style transfer<br><br>

문제<br>
- 입력이 매우 클 수 있다<br>
1000*1000*3 = 3백만 크기<br>
첫 은닉층 = 1000개<br>
전체 가중치 = 1000*3,000,000 크기 행렬<br><br>

2. 모서리 감지 예시<br>
어떻게 이미지의 모서리를 감지하는가<br><br>

1) 이미지에서 수직인 모서리를 감지한다<br>
2) 수평인 모서리를 감지한다<br><br>

세로 윤곽선 검출 - 합성곱 연산<br>
: 원래 이미지와 커널을 원소곱 후 전부 더해준다<br><br>

딥러닝 프레임워크에서는 Conv2d 함수를 사용한다<br><br>

3. 더 많은 모서리 감지 예시<br>
양과 음의 윤곽선의 차이 – 서로 다른 밝기의 전환<br>
밝은 곳 -> 어두운 곳 – 어 밝 어<br>
어두운 곳 -> 밝은 곳 – 밝 어 밝<br><br>

가로배열 필터 -> 수평 모서리 검출<br>

필터 종류<br>
1) sobel filter – 중간 부분의 픽셀에 더 중점을 둔다<br>
2) scharr filter – 3, 10 사용<br>
3) 딥러닝 – 9개 숫자를 고를 필요가 없다. 스스로 학습한다<br><br>

4. 패딩<br>
n*n 이미지를 f*f 필터로 합성곱을 한 결과 = n-f+1*n-f+1<br><br>

단점 2개<br>
1) 합성곱 연산을 할 때마다 이미지가 축소된다<br>
-> 수 백개의 층에서 각 층마다 축소된다면 모든 층을 거친 뒤에는 아주 작은 이미지만 남음<br>
2) 가장자리나 모서리의 픽셀은 결과 이미지에 덜 사용된다<br><br>

해결<br>
: 합성곱 연산을 하기 전에 이미지를 덧댄다 (0을 더하는 것이 일반적)<br>
n+2p-f+1*n+2p-f+1<br><br>

패딩을 얼마 만큼 할 것인가?<br>
1) 유효 합성곱 : 패딩이 없는 것<br>
2) 동일 합성곱 : 패딩을 한 뒤 결과 이미지의 크기가 기존 이미지와 동일<br>
p = (f-1)/2<br><br>

컴퓨터비전에서 필터가 거의 홀수인 이유<br>
1) 만약 f가 짝수라면 패딩이 비대칭이 된다<br>
2) 만약 홀수 크기의 필터가 있으면 중심 위치가 존재한다<br>
따라서 3*3 사용이 일반적. 5*5, 7*7도 사용<br><br>

5. 스트라이드<br>
스트라이드 : 필터의 이동 횟수<br><br>

n*n이미지를 f*f 필터로 합성곱을 하고 p의 패딩과 s 스트라이드를 가지면<br>
(n+2p-f)/s+1*(n+2p-f)/s+1<br>
만약에 소수점으로 만들었다면 내림을 하게 된다. 보통은 필터에 맞춰서 최대한 크기가 정수가 될수 있도록 패딩과 스트라이드 수치를 맞춘다.<br><br>

신호처리에서의 교차상관과 합성곱의 관계<br>
미러링 : 합성곱을 하기 전에 필터를 가로축과 세로축으로 뒤집는 연산을 해주는 것<br>
지금까지의 합성곱 연산은 미러링 과정을 생략했다 -> 프로그래밍에 영향x여서<br><br>

6. 입체형 이미지에서의 합성곱<br>
3D 필터를 사용<br>
(높이*넓이*채널수) * (높이*넓이*채널수)<br>
채널 : 색상 또는 입체형 이미지의 깊이, 이미지의 채널수 = 필터의 채널수<br>
각 채널 별로 필터는 모두 같은 것을 사용할 수도 있고 다른 것을 사용할 수도 있다.<br>
n-f+1*n-f+1*nc’<br>
가로와 세로처럼 두 개의 특성 또는 10개의 특성들을 검출할 수 있고 검출하고자 하는 특성의 수만큼 채널을 가지게 된다<br>
채널의 수 = 마지막 크기, 3D 입체형의 깊이<br><br>

7. 합성곱 네트워크의 한 계층 구성하기<br>
합성곱 신경망의 한 계층은 아래와 같이 구성된다<br>
합성곱 연산 → 편향 추가 → 활성화 함수<br>
활성화 함수는 비선형성을 적용하기 위함이다. 보통 ReLU 를 많이 사용한다<br><br>

예시에서 합성곱 연산을 할 때 두 개의 필터를 사용해서 27*2개 가짐<br><br>

만약 10개의 필터가 있고 각각 3*3*3 크기로 신경망의 한 계층에 있다면 이 층은 몇 개의 매개변수를 가질까?<br>
-> 각각의 필터는 3*3*3의 크기로 27개의 변수를 가진다. 편향을 더하면 28개의 변수를 가진다. 10개가 있기 때문에 28에 10을 곱하면 280개의 변수를 가진다. <br>

8. 간단한 합성곱 네트워크 예시<br>
합성곱 신경망의 크기는 깊어질수록 점점 줄어든다<br>
대부분의 신경망에는 합성곱 층, 풀링 층, 완전 연결 층으로 구성되어 있다<br><br>

9. 풀링층<br>
합성곱 신경망에서는 풀링 층을 사용해 표현의 크기를 줄임으로써 계산속도를 줄이고 특징을 더 잘 검출 해낼 수 있다.<br>
한 특성이 필터의 한 부분에서 검출되면 높은 수를 남기고 그렇지 않으면 작은 수를 남긴다<br><br>

풀링의 종류<br>
1) 최대 풀링 -> 이미지의 특징이 펄터의 한 부분에서 검출 되면 높은 수를 남기고 그렇지 않으면 다른 최대값들에 비해 상대적으로 작아져, 특징을 더 잘 남긴다<br>
2) 평균 풀링<br>
보통 최대 풀링을 사용한다<br><br>

10. CNN 예시<br>
합성곱 신경망의 분야에서는 두 종류의 관습이 있는데, 하나는 합성곱 층과 풀링 층을 하나의 층으로 보고, 다른 하나는 합성곱 층과 풀링 층을 각각의 층으로 간주 하는 것이다. 여기서는 전자의 방법을 사용한다. 풀링 층에 학습해야 할 변수가 없기 때문에 합성곱 층과 풀링 층을 하나로 간주한다.<br><br>

11. 왜 합성곱을 사용할까요?<br>
합성곱 신경망을 사용하면 변수를 적게 사용할 수 있다.<br><br>
합성곱 신경망이 이렇게 적은 변수를 필요로 하는 이유 : <br>
1) 변수 공유 - 어떤 한 부분에서 이미지의 특성을 검출하는 필터가 이미지의 다른 부분에서도 똑같이 적용되거나 도움이 된다.<br>
2) 희소 연결 - 출력값이 이미지의 일부(작은 입력값)에 영향을 받고, 나머지 픽셀들의 영향을 받지 않기 때문에, 과대적합을 방지할 수 있다.<br>
합성곱 신경망은 이동 불변성을 포착하는데도 용이하다. 이미지가 약간의 변형이 있어도 이를 포착할 수 있다.