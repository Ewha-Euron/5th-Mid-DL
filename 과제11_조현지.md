5. 하이퍼파라미터 튜닝<br>
<br>
1) 튜닝 프로세스<br>
다뤄야 할 하이퍼파라미터 :<br>
- 학습률 (α) : 중요1<br>
- 모멘텀(Momentum) 알고리즘의  \betaβ : 중요2, 기본값 0.9<br>
- 은닉 유닛의 수 : 중요2<br>
- 미니배치 크기 : 중요2<br>
- 은닉층의 개수 : 중요3<br>
- 학습률 감쇠(learning rate decay) 정도 : 중요3<br>
- 아담(Adam) 알고리즘의  β1, β2, ϵ <br>
<br>
어떤 값을 탐색할지 어떻게 정하는가?<br>
- 무작위 접근 방식 : 격자점이 아니라 무작위적으로 접근한다. 어떤 하이퍼파라미터가 문제 해결에 더 중요한지 미리 알 수 없기 때문이다.<br>
- 정밀화 접근 : 우선 전체 하이퍼파라미터 공간에서 탐색하여 좋은 점을 찾은 후, 그 근방에서 더 정밀하게 탐색하는 과정이다.<br>
<br>
2) 적절한 척도 선택하기<br>
무작위로 뽑는 것이 합리적인 하이퍼파라미터 :<br>
- 은닉 유닛의 수<br>
- 은닉층의 수<br>
<br>
학습률 α의 경우 :<br>
- 1 과 0.0001 사이의 값중에 균일하게 무작위 값을 고르게 되면, 90%의 값이 1 과 0.1 사이에 존재하기 때문에, 공평하다고 할 수 없다.<br>
- 따라서 선형척도대신 로그척도에서 하이퍼파라미터를 찾는 것이 합리적이다.<br>
- 위 예시에 따르면 0과 -4 사이에 균일하게 무작위로 고르고 10의 지수로 바꿔주는 것이다.<br>
<br>
지수 가중 이동 평균에 사용되는 β의 경우 :<br>
- 0.9 와 0.999 사이의 값을 탐색하는 것은 비합리적이기 때문에 1-β  를 취해준 후, 위의 예시와 마찬가지로 로그척도에서 무작위 값을 선택하여 탐색한다.<br>
<br>
왜 선형척도에서 샘플을 뽑은 것이 안좋을까?<br>
-> 위의 값들은 1에 가까울 수록 알고리즘 결과에 더 큰 영향을 끼치기 때문이다.<br>
<br>
3) 하이퍼파라미터 튜닝 실전<br>
하이퍼파라미터 튜닝 방법 2가지<br>
1. 모델 돌보기(baby sitting one model) = 판다 접근<br>
- 컴퓨터의 자원이 많이 필요하지 않거나, 적은 숫자의 모델을 한번에 학습 시킬 수 있을 때 사용한다.<br>
- 하나의 모델로 매일 성능을 지켜보면서, 학습 속도를 조금 씩 바꾸는 방식이다.<br>
2. 동시에 여러 모델 훈련(Training many models in parallel) = 캐비어 접근<br>
- 컴퓨터의 자원이 충분히 많아 여러 모델을 한번에 학습 시킬 수 있을 때 사용한다.<br>

