머신러닝 어플리케이션 설정하기<br>
<br>
Train/Dev/Test 세트<br>
신경망을 훈련시킬 때 결정 내려야 할 것<br>
신경망이 몇 개의 층을 가지는지<br>
각 층이 몇 개의 hidden unit을 가지는지<br>
학습률과 활성화 함수는 무엇인지<br>
(아이디어 -> 코드 -> 실험) 반복하면서 하이퍼파라미터에 대한 선택을 개선한다<br>
<br>
훈련 세트: 훈련을 위해 사용되는 데이터<br>
개발 세트: 다양한 모델 중 어떤 모델이 좋은 성능을 나타내는지 확인<br>
테스트 세트: 모델이 얼마나 잘 작동하는지 확인<br>
<br>
요즘은 훈련 세트로 데이터를 많이 사용하는 것이 트렌드. 두 개의 알고리즘 중 어느 것이 더 좋은지 평가할 정도만 데이터 있으면 된다.<br>
데이터 백만개일 때 – 98%/1%/1%.<br>
백만개보다 많을 때 – 99.5%/0.25%/0.25% or 99.5%/0.4%/0.1%.<br>
훈련 세트는 인터넷에서 긁어온 사진이고 개발과 테스트 세트는 사용자가 핸드폰으로 찍은 사진일 경우(저해상도) - 개발과 테스트 분포가 같은 비율인 것이 좋다.<br>
테스트 세트는 없어도 괜찮다 – 비편향 추정이 필요 없는 경우에 이 경우에는 보통 훈련/테스트 세트로 부른다<br>
<br>
편향/분산<br>
높은 편향값 -> 데이터의 과소적합<br>
높은 분산 -> 데이터의 과대적합<br>
중간 단계의 복잡함 -> 딱 맞는 형태<br>
특성을 x_1, x_2만 갖는 2차원 예제에서만 데이터를 나타내거나 결정 경계를 시각화할 수 있다<br>
<br>
Case 1:<br>
훈련 세트 오차: 1%<br>
개발 세트 오차: 11%<br>
-> 훈련 세트에 과대적합이 되어서 개발 세트가 있는 교차 검증 세트에서 일반화되지 못함<br>
-> 높은 분산을 갖는다<br>
<br>
Case 2:<br>
훈련 세트 오차: 15%<br>
개발 세트 오차: 16%<br>
인간의 오차: 0%<br>
-> 훈련 데이터에 대해서 잘 맞지 않는다면 과소적합된다<br>
-> 높은 편향을 갖는다<br>
-> 반면 합리적인 수준의 개발 세트에서 일반화된다 (1%밖에 나쁘지 않으므로)<br>
<br>
Case 3:<br>
훈련 세트 오차: 15%<br>
개발 세트 오차: 30%<br>
-> 훈련 세트에 잘 맞지 않는다<br>
-> 높은 편향을 갖는다 + 높은 분산을 갖는다<br>
<br>
Case 4:<br>
훈련 세트 오차: 0.5%<br>
개발 세트 오차: 1%<br>
-> 낮은 편향을 갖는다 + 낮은 분산을 갖는다<br>
<br>
베이지안 오차(최적 오차)가 0%라는 가정 but 최적 오차가 15%라는 가정 -> Case 2는 합당하다<br>
-> 높은 편향이 아니고 낮은 분산<br>
<br>
이미지가 흐릿하여 인간 혹은 시스템도 잘 분류하지 못하는 경우<br>
-> 베이즈 오차는 훨씬 커질 것이고, 분석에 대한 세부 방식도 달라진다<br>
<br>
훈련 세트 오차를 확인함으로써 최소한 훈련 데이터에서 얼마나 알고리즘이 적합한지 감을 잡을 수 있다 / 편향 문제가 있는지 알 수 있다<br>
<br>
훈련 세트에서 개발 세트로 갈 때 오차가 얼마나 커지는지에 따라서 분산 문제가 얼마나 나쁜지에 대한 감을 잡을 수 있다 / 훈련 세트에서 개발 세트로 일반화를 잘 하느냐에 따라 분산에 대한 감이 달라진다<br>
(베이즈 오차가 꽤 작고, 훈련 세트와 개발 세트가 같은 확률 분포에서 왔다는 가정 하)<br>
<br>
높은 편향과 높은 분산 -> 그래프에서 많은 굴곡을 가져서 과대적합된다<br>
<br>
거의 선형이지만 곡선이나 이차 함수가 필요하기 때문에 높은 편향을 갖는다<br>
잘못 라벨링된 샘플을 맞추기 위해 너무 많은 굴곡을 갖기 때문에 높은 분산을 갖는다<br>
머신러닝을 위한 기본 레시피
<br>
#1 편향 문제 줄이기<br>
알고리즘이 높은 편향을 가지는지 평가하기 위해서는 훈련 세트 혹은 훈련 데이터의 성능을 봐야 한다<br>
높은 편향을 가져서 훈련 세트에도 잘 맞지 않는다면 -> 더 많은 hidden unit을 갖는 네트워크를 선택해야 한다 or 더 오랜 시간 훈련시키거나 다른 발전된 최적화 알고리즘을 사용한다<br>
(편향 문제를 해결할 때까지)<br>
베이즈 오차가 그렇게 높지 않은 경우는 크게 훈련하는 경우 최소한 훈련 세트에 대해서는 잘 맞을 것이다<br>
<br>
#2 분산 문제 해결하기<br>
꽤 좋은 훈련 세트 성능에서 꽤 좋은 개발 세트 성능을 일반화할 수 있는가<br>
높은 분산 문제 -> 데이터를 더 얻어 해결한다 or 과대적합을 줄이기 위해 정규화를 시도한다 or 다른 신경망 아키텍처를 찾는 것을 시도한다<br>
(낮은 편향과 분산을 찾을 때까지 계속 시도하고 반복한다)<br>
<br>
중요한 것<br>
<br>
높은 편향이나 분산이냐에 따라 시도해볼 수 있는 방법이 아주 다르다. 그래서 주로 훈련과 개발 세트를 편향이나 분산 문제가 있는지 진단하는데 사용한다<br>
편향-분산 트레이드오프. 시도할 수 있는 많은 것들이 편향을 증가시키고 분산을 감소시키거나 편향을 감소시키고 분산을 증가시키기 때문이다. 딥러닝 빅데이터 시대에는 더 큰 네트워크를 훈련시키는 것이 대부분 분산을 해치지 않고 편향만 감소시킨다 / 더 많은 데이터를 얻는 것도 대부분 편향을 해치지 않고 분산을 감소시킨다. -> 편향과 분산의 균형을 신경써야 하는 트레이드오프가 훨씬 적다<br>
