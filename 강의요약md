# 강의 요약

## 튜닝 프로세스

- 하이퍼파라미터 찾는 방법?
- 체계적인 하이퍼파라미터 튜닝

---

Hyperparameters

- **학습률
- *모멘텀 → 아담의 경우엔 2개 / default = 0.9
- layer 수
- *hidden units 수
- 학습률 감쇠
- *mini-batch size → 효율적 알고리즘을 위해

→ 그러나 사람에 따라 다름

---

Try random values: Don’t use a grid → 하이퍼파라미터의 수가 적을 때 주로 사용

random할 때가 더 효율적일 수 있다

ex) 더 중요한 hyperparameterf을 기준으로 grid 값을 사용할 때 그 다양성이 감소함 / 랜덤한 값으로 할 때 다양한 값으로 접근할 수 있다

일반적 방법 중 하나 : 정밀화 접근 → 최적의 값을 보이는 범위를 찾아 더 세분화하기

## 적절한 척도 선택하기

- 무작위로 하이퍼파라미터를 찾는 것이 더 효율적인 탐색 when choose 은닉 유닛의 수, 은닉층의 수→ 그러나 학습률의 경우 완전한 무작위는 비효율적이므로 적절한 척도를 정하는 것이 중요하다
    - 1과 0.0001의 값 중에 90%가 1과 0.1 사이에 존재하기 때문에 공평하다고 볼 수 없다. 따라서 선형 척도 대신 로그 척도에서 하이퍼파라미터를 찾는 것이 합리적 (0과 -4 사이에 균일하게 무작위로 고르고 10의 지수로 바꿔주는 것)
- ex. 값의 범위 50~100 중에 무작위한 값을 정하여 레이어 숫자를 지정한다고 했을 때 층의 숫자를 선별
    
    → 이 때 선형 척도 대신 로그 척도에 기반하여 추측하는 것이 우수한 효율을 보인다.
    
- 다른 예시로, 지수 가중 이동 평균에서 사용되는  *β*  입니다. 마찬가지로 0.9 와 0.999 사이의 값을 탐색하는 것은 비합리적이기 때문에 1- *β*  를 취해준 후, 위의 예시와 마찬가지로 로그척도에서 무작위 값을 선택하여 탐색합니다.
- 선형 척도에서 뽑는 것 → *β* 값의 변화에 따라 결과값이 크게 바뀐다. 1에 가까워질 수록 결과에 큰 영향을 받는다.
- *β가* 1과 가까운 곳에서 더 조밀하게 샘플을 뽑는다 (1에 가까워질 수록 결과에 대한 민감도가 증가하기 때문에)

## ****하이퍼파라미터 튜닝 실전****

새로운 모델 발전으로 하이퍼파라미터의 재튜닝이 필요

1. Babysitting one model : 데이터는 방대하지만 CPU, GPU 등의 부진으로 적은 숫자의 모델을 학습하는 과정에서 사용 / 0일차부터 무작위의 값에 대한 학습을 시작, 비용함수에 대한 감소가 진행…. 
    
    → 매일 매일 모델의 학습 정도, 성능을 지켜보면서 업데이트하는 것 / 모델을 동시에 학습시킬 자원이 충분하지 않을 때 사용
    
    → 많은 데이터가 사용되는 경우에는 동시에 여러 모델을 돌리는 것이 불가능, 하나의 모델에 집중해 매개변수를 조금씩 조절하며 잘 작동하게끔 확인하는 일, 그러나 다른 모델과의 비교도 반드시 필요하다
    
2. Training many models in parallel : 며칠에 걸쳐 스스로 학습하게 하는 것, 동시에 다른 모델의 하이퍼파라미터를 다룬다. 동시에 여러 조건의 hyperparamer를 다룰 수 있다.